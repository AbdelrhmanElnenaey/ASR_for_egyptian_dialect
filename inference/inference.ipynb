{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8941273,"sourceType":"datasetVersion","datasetId":5380028},{"sourceId":9018921,"sourceType":"datasetVersion","datasetId":5434711},{"sourceId":9019051,"sourceType":"datasetVersion","datasetId":5434804},{"sourceId":9021594,"sourceType":"datasetVersion","datasetId":5436543},{"sourceId":9021642,"sourceType":"datasetVersion","datasetId":5436575}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install Required Packages","metadata":{}},{"cell_type":"code","source":"# !git clone https://github.com/AbdelrhmanElnenaey/ASR_for_egyptian_dialect\n%cd ASR_for_egyptian_dialect","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:20:30.296203Z","iopub.execute_input":"2024-07-24T16:20:30.296614Z","iopub.status.idle":"2024-07-24T16:20:30.303566Z","shell.execute_reply.started":"2024-07-24T16:20:30.296582Z","shell.execute_reply":"2024-07-24T16:20:30.302446Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/working/ASR_for_egyptian_dialect\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install wget\n!apt-get install -y sox libsndfile1 ffmpeg\n!pip install text-unidecode\n\nBRANCH = 'main'\n!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[asr]\n\n!pip install torchaudio -f https://download.pytorch.org/whl/torch_stable.html\n!pip install gdown\n!pip install demucs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modify Extract Embeddings Function in NeMo Clustering Diarizer","metadata":{}},{"cell_type":"code","source":"import site\nimport os\nsite_packages_path = site.getsitepackages()[0]\nfile_path = os.path.join(site_packages_path, 'nemo', 'collections', 'asr', 'models', 'clustering_diarizer.py')\nprint(f\"File path: {file_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:26:07.872254Z","iopub.execute_input":"2024-07-24T16:26:07.873168Z","iopub.status.idle":"2024-07-24T16:26:07.879313Z","shell.execute_reply.started":"2024-07-24T16:26:07.873125Z","shell.execute_reply":"2024-07-24T16:26:07.878145Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"File path: /opt/conda/lib/python3.10/site-packages/nemo/collections/asr/models/clustering_diarizer.py\n","output_type":"stream"}]},{"cell_type":"code","source":"modifications = \"\"\"\ndef _extract_embeddings(self, manifest_file: str, scale_idx: int, num_scales: int):\n    print(\"INSIDE MODIFIED EXTRACT EMBEDDINGS..\")\n    import nemo.collections.asr as nemo_asr\n    self._ecapa_tdnn_model = nemo_asr.models.EncDecSpeakerLabelModel.from_pretrained(model_name='ecapa_tdnn')\n    self._ecapa_tdnn_model.eval()\n\n    logging.info(\"Extracting embeddings for Diarization\")\n    self._setup_spkr_test_data(manifest_file)\n    self.embeddings = {}\n    self._speaker_model.eval()\n    self.time_stamps = {}\n\n    all_embs = torch.empty([0])\n    for test_batch in tqdm(\n        self._speaker_model.test_dataloader(),\n        desc=f'[{scale_idx+1}/{num_scales}] extract embeddings',\n        leave=True,\n        disable=not self.verbose,\n    ):\n        test_batch = [x.to(self._speaker_model.device) for x in test_batch]\n        audio_signal, audio_signal_len, labels, slices = test_batch\n        with autocast():\n            _, embs = self._speaker_model.forward(input_signal=audio_signal, input_signal_length=audio_signal_len)\n            embs_ecapa = self._ecapa_tdnn_model.forward(input_signal=audio_signal, input_signal_length=audio_signal_len)\n            embs = torch.cat((embs, embs_ecapa[0]), dim=-1)\n            emb_shape = embs.shape[-1]\n            embs = embs.view(-1, emb_shape)\n            all_embs = torch.cat((all_embs, embs.cpu().detach()), dim=0)\n        del test_batch\n\n    with open(manifest_file, 'r', encoding='utf-8') as manifest:\n        for i, line in enumerate(manifest.readlines()):\n            line = line.strip()\n            dic = json.loads(line)\n            uniq_name = get_uniqname_from_filepath(dic['audio_filepath'])\n            if uniq_name in self.embeddings:\n                self.embeddings[uniq_name] = torch.cat((self.embeddings[uniq_name], all_embs[i].view(1, -1)))\n            else:\n                self.embeddings[uniq_name] = all_embs[i].view(1, -1)\n            if uniq_name not in self.time_stamps:\n                self.time_stamps[uniq_name] = []\n            start = dic['offset']\n            end = start + dic['duration']\n            self.time_stamps[uniq_name].append([start, end])\n\n    if self._speaker_params.save_embeddings:\n        embedding_dir = os.path.join(self._speaker_dir, 'embeddings')\n        if not os.path.exists(embedding_dir):\n            os.makedirs(embedding_dir, exist_ok=True)\n\n        prefix = get_uniqname_from_filepath(manifest_file)\n        name = os.path.join(embedding_dir, prefix)\n        self._embeddings_file = name + f'_embeddings.pkl'\n        pkl.dump(self.embeddings, open(self._embeddings_file, 'wb'))\n        logging.info(\"Saved embedding files to {}\".format(embedding_dir))\n\n\"\"\"\n\nif os.path.isfile(file_path):\n    with open(file_path, 'r') as file:\n        file_data = file.read()\n\n    # find the location to insert the new function\n    start_idx = file_data.find(\"def _extract_embeddings\")\n    end_idx = file_data.find(\"def \", start_idx + 1) if file_data.find(\"def \", start_idx + 1) != -1 else len(file_data)\n\n    indent = \" \" * 4\n    indented_modifications = \"\\n\".join([indent + line if line.strip() else line for line in modifications.split('\\n')])\n\n    # create new file content\n    new_file_data = file_data[:start_idx] + indented_modifications + \"\\n\\n\" + indent + file_data[end_idx:]\n\n    # Write the modified content back to the file\n    with open(file_path, 'w') as file:\n        file.write(new_file_data)\n\n    print(f\"Modified function in {file_path}.\")\nelse:\n    print(f\"File not found: {file_path}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:26:08.917014Z","iopub.execute_input":"2024-07-24T16:26:08.917438Z","iopub.status.idle":"2024-07-24T16:26:08.931903Z","shell.execute_reply.started":"2024-07-24T16:26:08.917409Z","shell.execute_reply":"2024-07-24T16:26:08.930896Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Modified function in /opt/conda/lib/python3.10/site-packages/nemo/collections/asr/models/clustering_diarizer.py.\n","output_type":"stream"}]},{"cell_type":"code","source":"## ONLY ON KAGGLE\n## You will need to restart the kernel after running this cell\n## Do not make factory reset, just restart the kernel\n\n\n# package_path = os.path.dirname(package_name.__file__)\nfile_to_edit = '/opt/conda/lib/python3.10/site-packages/nemo/collections/asr/parts/submodules/rnnt_decoding.py'  # Update 'subdir' and 'file.py' as needed\n\n# Read the file\nwith open(file_to_edit, 'r', encoding='utf-8') as file:\n    lines = file.readlines()\n\n# Make your edits (for example, replacing a specific line)\nfor i, line in enumerate(lines):\n#     print(line)\n    if '# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.' in line:\n        lines[i] = 'import copy\\n'\n    \n# Write the file back\nwith open(file_to_edit, 'w', encoding='utf-8') as file:\n    file.writelines(lines)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T13:30:01.558229Z","iopub.execute_input":"2024-07-24T13:30:01.559150Z","iopub.status.idle":"2024-07-24T13:30:01.570150Z","shell.execute_reply.started":"2024-07-24T13:30:01.559112Z","shell.execute_reply":"2024-07-24T13:30:01.569055Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# You Will Need To Restart the Kernel After the Modification","metadata":{}},{"cell_type":"code","source":"os._exit(00)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import gdown\nimport argparse\nimport torch\nimport soundfile as sf\nimport os\nimport gdown\nimport nemo.collections.asr as nemo_asr\nfrom ruamel.yaml import YAML\nfrom omegaconf import OmegaConf, open_dict\nimport json\nimport subprocess\nimport logging\nfrom pydub import AudioSegment\nimport numpy as np\nfrom IPython.display import Audio, display\nimport librosa\nimport wget\nimport matplotlib.pyplot as plt\nimport nemo\nimport glob\nimport pprint\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:31:46.150924Z","iopub.execute_input":"2024-07-24T16:31:46.151627Z","iopub.status.idle":"2024-07-24T16:32:00.844810Z","shell.execute_reply.started":"2024-07-24T16:31:46.151595Z","shell.execute_reply":"2024-07-24T16:32:00.843979Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/ASR_for_egyptian_dialect","metadata":{"execution":{"iopub.status.busy":"2024-07-24T13:29:40.147934Z","iopub.execute_input":"2024-07-24T13:29:40.148627Z","iopub.status.idle":"2024-07-24T13:29:40.155706Z","shell.execute_reply.started":"2024-07-24T13:29:40.148591Z","shell.execute_reply":"2024-07-24T13:29:40.154467Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/ASR_for_egyptian_dialect\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# ASR Inference","metadata":{}},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef load_asr_model(ckpt_path):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(device)\n    if(not os.path.exists(ckpt_path)):\n        url = \"https://drive.google.com/file/d/1faLSvzXVcZd_lvBXxxdWYyBGyGnC2ijL/view?usp=drive_link\"\n        gdown.download(url, ckpt_path, quiet=False, fuzzy=True)\n\n    config_path = '/kaggle/input/config2/FC-transducer-inference.yaml'\n    yaml = YAML(typ='safe')\n    with open(config_path) as f:\n        params = yaml.load(f)\n    params['model'].pop('test_ds')\n    conf = OmegaConf.create(params)\n\n    model = nemo_asr.models.EncDecRNNTBPEModel(cfg=conf['model']).to(device)\n    decoding_cfg = model.cfg.decoding\n    with open_dict(decoding_cfg):\n        decoding_cfg.preserve_alignments = True\n        decoding_cfg.compute_timestamps = True\n        decoding_cfg.strategy = 'greedy'\n#         decoding_cfg.beam.beam_size = 3 \n        model.change_decoding_strategy(decoding_cfg)\n    model.load_state_dict(torch.load(ckpt_path)['state_dict'])\n    model.eval()\n    return model\n    \n\ndef create_parser():\n    parser = argparse.ArgumentParser(description=\"ASR Inference\")\n    parser.add_argument(\"--asr_model\", type=str, help=\"Path to the ASR model checkpoint\", default=\"asr_model.ckpt\")\n    parser.add_argument(\"--data_dir\", type=str, help=\"Path to the directory containing test data\", default=\"data/adapt\")\n    parser.add_argument(\"--output\", type=str, help=\"Path to the output file\", default=\"results.csv\")\n    return parser\n\ndef infere(model, audio):\n    hypotheses = model.transcribe([audio], return_hypotheses=True)\n    if type(hypotheses) == tuple and len(hypotheses) == 2:\n        hypotheses = hypotheses[0]\n    return hypotheses\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:32:00.846265Z","iopub.execute_input":"2024-07-24T16:32:00.846793Z","iopub.status.idle":"2024-07-24T16:32:00.886329Z","shell.execute_reply.started":"2024-07-24T16:32:00.846764Z","shell.execute_reply":"2024-07-24T16:32:00.885429Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Generate Manifest File for Diarization","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/ASR_for_egyptian_dialect\ndata_dir = '/kaggle/input/diarization/wavs'\nwith open(\"audio_files.txt\", \"w\") as f:\n    for file in os.listdir(data_dir):\n        f.write(os.path.join(os.getcwd(), data_dir, file) + \"\\n\")\n        \n\n!python /kaggle/working/ASR_for_egyptian_dialect/NeMo/scripts/speaker_tasks/pathfiles_to_diarize_manifest.py \\\n--paths2audio_files audio_files.txt \\\n--manifest_filepath test_manifest.json \\\n--add_duration\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing\nThe following script takes the original manifest and applies source separation to the wav files and generates a new manifest","metadata":{}},{"cell_type":"code","source":"input_manifest_path = '/kaggle/working/ASR_for_egyptian_dialect/test_manifest.json'\noutput_manifest_path = '/kaggle/working/ASR_for_egyptian_dialect/test_manifest_vocals.json'\ntemp_output_dir = 'temp_outputs'\nmono_output_dir = '/kaggle/working/ASR_for_egyptian_dialect/temp_outputs_mono'\nos.makedirs(mono_output_dir, exist_ok=True)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(input_manifest_path, 'r') as f:\n    manifest = [json.loads(line) for line in f]\n\nnew_manifest = []\nfor entry in manifest:\n    audio_filepath = entry['audio_filepath']\n    base_name = os.path.splitext(os.path.basename(audio_filepath))[0]\n\n    try:\n        result = subprocess.run(\n            [\n                \"python3\",\n                \"-m\",\n                \"demucs.separate\",\n                \"-n\",\n                \"htdemucs\",\n                \"--two-stems=vocals\",\n                audio_filepath,\n                \"-o\",\n                temp_output_dir\n            ],\n            check=True,\n            capture_output=True,\n            text=True\n        )\n        # rename the output file to match the original base name (for compatibility with NeMo)\n        original_vocal_filepath = os.path.join(temp_output_dir, \"htdemucs\", base_name, \"vocals.wav\")\n        vocal_filepath = os.path.join(temp_output_dir, \"htdemucs\", f\"{base_name}.wav\")\n        if os.path.exists(original_vocal_filepath):\n            os.rename(original_vocal_filepath, vocal_filepath)\n        else:\n            raise FileNotFoundError(f\"Expected output file not found: {original_vocal_filepath}\")\n    except (subprocess.CalledProcessError, FileNotFoundError) as e:\n        logging.warning(f\"Source splitting failed for {audio_filepath}, using original audio file. Error: {str(e)}\")\n        vocal_filepath = audio_filepath\n\n    # Convert to mono\n    sound = AudioSegment.from_file(vocal_filepath).set_channels(1)\n    mono_vocal_filepath = os.path.join(mono_output_dir, f\"{base_name}.wav\")\n    sound.export(mono_vocal_filepath, format=\"wav\")\n\n    # Update the manifest entry with the new audio filepath\n    new_entry = entry.copy()\n    new_entry['audio_filepath'] = mono_vocal_filepath\n    new_manifest.append(new_entry)\n\n# Save the new manifest\nwith open(output_manifest_path, 'w') as f:\n    for entry in new_manifest:\n        json.dump(entry, f)\n        f.write('\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run ASR Inference\nReturns\n\n`word_hyp` : A list of all the words output from the ASR\n\n`word_ts_hyp`: A list of tuples, each tuple contains the start and end timestamp of the corresponding word.","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/ASR_for_egyptian_dialect\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndata_dir = '/kaggle/input/diarization/wavs'\nasr_model = load_asr_model('/kaggle/input/asr-model/asr_model.ckpt')\nasr_model.to(device)\n\n\nword_hyp = {}\nword_ts_hyp = {}\n\n\nwith open('/kaggle/working/results2.csv', \"w+\", encoding='utf-8') as fp:\n    fp.write(\"audio,transcript,start,end\\n\")\n\nfor filename in os.listdir(data_dir):\n    if filename.endswith('.wav'):\n        audio, sr = sf.read(os.path.join(data_dir, filename), dtype='float32')\n        audio_path = os.path.join(data_dir, filename)\n        with torch.no_grad():\n            rv = infere(model=asr_model, audio=audio_path)\n\n        timestamp_dict = rv[0].timestep\n        time_stride = 8 * asr_model.cfg.preprocessor.window_stride\n        word_timestamps = timestamp_dict['word']\n\n        words = []\n        word_timestamps_list = []\n\n        with open('/kaggle/working/results2.csv', \"a+\") as fp:\n            for i, stamp in enumerate(word_timestamps):\n                start = stamp['start_offset'] * time_stride\n                end = stamp['end_offset'] * time_stride\n                transcription = stamp['word']\n\n                words.append(transcription)\n                word_timestamps_list.append([start, end])\n\n\n                fp.write(f\"{filename},{transcription},{start},{end}\\n\")\n            unique_id = os.path.splitext(filename)[0] \n            word_hyp[unique_id] = words\n            word_ts_hyp[unique_id] = word_timestamps_list","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:36:02.788539Z","iopub.execute_input":"2024-07-24T16:36:02.789567Z","iopub.status.idle":"2024-07-24T16:36:17.105054Z","shell.execute_reply.started":"2024-07-24T16:36:02.789524Z","shell.execute_reply":"2024-07-24T16:36:17.104092Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/ASR_for_egyptian_dialect\ncuda\n[NeMo I 2024-07-24 16:36:02 mixins:173] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n","output_type":"stream"},{"name":"stderr","text":"[NeMo W 2024-07-24 16:36:03 audio_to_text_dataset:830] Could not load dataset as `manifest_filepath` was None. Provided config : {'manifest_filepath': None, 'sample_rate': 16000, 'batch_size': 32, 'shuffle': True, 'num_workers': 8, 'pin_memory': True, 'max_duration': 16.7, 'min_duration': 0.1, 'is_tarred': False, 'tarred_audio_filepaths': None, 'shuffle_n': 2048, 'bucketing_strategy': 'fully_randomized', 'bucketing_batch_size': None}\n[NeMo W 2024-07-24 16:36:03 audio_to_text_dataset:830] Could not load dataset as `manifest_filepath` was None. Provided config : {'manifest_filepath': None, 'sample_rate': 16000, 'batch_size': 32, 'shuffle': False, 'use_start_end_token': False, 'num_workers': 8, 'pin_memory': True}\n","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:36:03 features:305] PADDING: 0\n","output_type":"stream"},{"name":"stderr","text":"[NeMo W 2024-07-24 16:36:04 nemo_logging:349] /opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n      warnings.warn(\"dropout option adds dropout after all but last \"\n    \n","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:36:04 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n[NeMo I 2024-07-24 16:36:04 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n[NeMo I 2024-07-24 16:36:04 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n[NeMo I 2024-07-24 16:36:04 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n[NeMo I 2024-07-24 16:36:04 rnnt_bpe_models:492] Changed decoding strategy to \n    model_type: rnnt\n    strategy: greedy\n    compute_hypothesis_token_set: false\n    preserve_alignments: true\n    confidence_cfg:\n      preserve_frame_confidence: false\n      preserve_token_confidence: false\n      preserve_word_confidence: false\n      exclude_blank: true\n      aggregation: min\n      tdt_include_duration: false\n      method_cfg:\n        name: entropy\n        entropy_type: tsallis\n        alpha: 0.33\n        entropy_norm: exp\n        temperature: DEPRECATED\n    fused_batch_size: null\n    compute_timestamps: true\n    compute_langs: false\n    word_seperator: ' '\n    rnnt_timestamp_type: all\n    greedy:\n      max_symbols_per_step: 10\n      preserve_alignments: false\n      preserve_frame_confidence: false\n      tdt_include_duration_confidence: false\n      confidence_method_cfg:\n        name: entropy\n        entropy_type: tsallis\n        alpha: 0.33\n        entropy_norm: exp\n        temperature: DEPRECATED\n      loop_labels: true\n      use_cuda_graph_decoder: true\n      max_symbols: 10\n    beam:\n      beam_size: 5\n      search_type: default\n      score_norm: true\n      return_best_hypothesis: true\n      tsd_max_sym_exp_per_step: 50\n      alsd_max_target_len: 2.0\n      nsc_max_timesteps_expansion: 1\n      nsc_prefix_alpha: 1\n      maes_num_steps: 2\n      maes_prefix_alpha: 1\n      maes_expansion_gamma: 2.3\n      maes_expansion_beta: 2\n      language_model: null\n      softmax_temperature: 1.0\n      preserve_alignments: false\n      ngram_lm_model: null\n      ngram_lm_alpha: 0.0\n      hat_subtract_ilm: false\n      hat_ilm_weight: 0.0\n      tsd_max_sym_exp: 50\n    temperature: 1.0\n    durations: []\n    big_blank_durations: []\n    \n","output_type":"stream"},{"name":"stderr","text":"Transcribing: 100%|██████████| 1/1 [00:08<00:00,  8.40s/it]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Diarization Inference","metadata":{}},{"cell_type":"code","source":"pp = pprint.PrettyPrinter(indent=4)\n\ndata_dir = \"/kaggle/working/diarization_output\"\nos.makedirs('/kaggle/working/diarization_output',exist_ok=True)\n\nDOMAIN_TYPE = \"general\" # Can be meeting or telephonic based on domain type of the audio file\nCONFIG_FILE_NAME = f\"diar_infer_{DOMAIN_TYPE}.yaml\"\n\nCONFIG_URL = f\"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_tasks/diarization/conf/inference/{CONFIG_FILE_NAME}\"\n\nif not os.path.exists(os.path.join(data_dir,CONFIG_FILE_NAME)):\n    CONFIG = wget.download(CONFIG_URL, data_dir)\nelse:\n    CONFIG = os.path.join(data_dir,CONFIG_FILE_NAME)\n\ncfg = OmegaConf.load(CONFIG)\ncfg.diarizer.collar = 0\ncfg.diarizer.vad.parameters.window_length_in_sec=0.63 #1.2\ncfg.diarizer.vad.parameters.shift_length_in_sec=0.05 #0.3\ncfg.diarizer.manifest_filepath = '/kaggle/working/ASR_for_egyptian_dialect/test_manifest_vocals.json'\n\npretrained_speaker_model='titanet_large'\ncfg.diarizer.out_dir = data_dir #Directory to store intermediate files and prediction outputs\ncfg.diarizer.speaker_embeddings.model_path = pretrained_speaker_model\ncfg.diarizer.clustering.parameters.oracle_num_speakers=False\n\ncfg.diarizer.vad.model_path = 'vad_multilingual_marblenet'\ncfg.diarizer.oracle_vad = False\ncfg.diarizer.asr.parameters.asr_based_vad = False\n\nprint(OmegaConf.to_yaml(cfg))","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:38:52.259612Z","iopub.execute_input":"2024-07-24T16:38:52.260499Z","iopub.status.idle":"2024-07-24T16:38:52.325921Z","shell.execute_reply.started":"2024-07-24T16:38:52.260467Z","shell.execute_reply":"2024-07-24T16:38:52.325039Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"name: ClusterDiarizer\nnum_workers: 1\nsample_rate: 16000\nbatch_size: 64\ndevice: null\nverbose: true\ndiarizer:\n  manifest_filepath: /kaggle/input/manifest/input_manifest.json\n  out_dir: /kaggle/working/diarization_output3\n  oracle_vad: false\n  collar: 0\n  ignore_overlap: true\n  vad:\n    model_path: vad_multilingual_marblenet\n    external_vad_manifest: null\n    parameters:\n      window_length_in_sec: 0.95\n      shift_length_in_sec: 0.05\n      smoothing: false\n      overlap: 0.5\n      onset: 0.5\n      offset: 0.3\n      pad_onset: 0.2\n      pad_offset: 0.2\n      min_duration_on: 0.5\n      min_duration_off: 0.5\n      filter_speech_first: true\n  speaker_embeddings:\n    model_path: titanet_large\n    parameters:\n      window_length_in_sec:\n      - 1.9\n      - 1.2\n      - 0.5\n      shift_length_in_sec:\n      - 0.95\n      - 0.6\n      - 0.25\n      multiscale_weights:\n      - 1\n      - 1\n      - 1\n      save_embeddings: true\n  clustering:\n    parameters:\n      oracle_num_speakers: false\n      max_num_speakers: 8\n      enhanced_count_thres: 80\n      max_rp_threshold: 0.25\n      sparse_search_volume: 10\n      maj_vote_spk_count: false\n      chunk_cluster_count: 50\n      embeddings_per_chunk: 10000\n  msdd_model:\n    model_path: null\n    parameters:\n      use_speaker_model_from_ckpt: true\n      infer_batch_size: 25\n      sigmoid_threshold:\n      - 0.7\n      seq_eval_mode: false\n      split_infer: true\n      diar_window_length: 50\n      overlap_infer_spk_limit: 5\n  asr:\n    model_path: null\n    parameters:\n      asr_based_vad: false\n      asr_based_vad_threshold: 1.0\n      asr_batch_size: null\n      decoder_delay_in_sec: null\n      word_ts_anchor_offset: null\n      word_ts_anchor_pos: start\n      fix_word_ts_with_VAD: false\n      colored_text: false\n      print_time: true\n      break_lines: false\n    ctc_decoder_parameters:\n      pretrained_language_model: null\n      beam_width: 32\n      alpha: 0.5\n      beta: 2.5\n    realigning_lm_parameters:\n      arpa_language_model: null\n      min_number_of_words: 3\n      max_number_of_words: 10\n      logprob_diff_threshold: 1.2\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from nemo.collections.asr.parts.utils.diarization_utils import OfflineDiarWithASR\nasr_diar_offline = OfflineDiarWithASR(cfg.diarizer)\ndiar_hyp, diar_score = asr_diar_offline.run_diarization(cfg, word_ts_hyp)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:39:00.580478Z","iopub.execute_input":"2024-07-24T16:39:00.581188Z","iopub.status.idle":"2024-07-24T16:40:03.145454Z","shell.execute_reply.started":"2024-07-24T16:39:00.581156Z","shell.execute_reply":"2024-07-24T16:40:03.144450Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[NeMo I 2024-07-24 16:39:00 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n[NeMo I 2024-07-24 16:39:00 cloud:68] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/vad_multilingual_marblenet/versions/1.10.0/files/vad_multilingual_marblenet.nemo to /root/.cache/torch/NeMo/NeMo_2.0.0rc2/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n[NeMo I 2024-07-24 16:39:01 common:826] Instantiating model from pre-trained checkpoint\n","output_type":"stream"},{"name":"stderr","text":"[NeMo W 2024-07-24 16:39:01 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n    Train config : \n    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n    sample_rate: 16000\n    labels:\n    - background\n    - speech\n    batch_size: 256\n    shuffle: true\n    is_tarred: false\n    tarred_audio_filepaths: null\n    tarred_shard_strategy: scatter\n    augmentor:\n      shift:\n        prob: 0.5\n        min_shift_ms: -10.0\n        max_shift_ms: 10.0\n      white_noise:\n        prob: 0.5\n        min_level: -90\n        max_level: -46\n        norm: true\n      noise:\n        prob: 0.5\n        manifest_path: /manifests/noise_0_1_musan_fs.json\n        min_snr_db: 0\n        max_snr_db: 30\n        max_gain_db: 300.0\n        norm: true\n      gain:\n        prob: 0.5\n        min_gain_dbfs: -10.0\n        max_gain_dbfs: 10.0\n        norm: true\n    num_workers: 16\n    pin_memory: true\n    \n[NeMo W 2024-07-24 16:39:01 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n    Validation config : \n    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n    sample_rate: 16000\n    labels:\n    - background\n    - speech\n    batch_size: 256\n    shuffle: false\n    val_loss_idx: 0\n    num_workers: 16\n    pin_memory: true\n    \n[NeMo W 2024-07-24 16:39:01 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n    Test config : \n    manifest_filepath: null\n    sample_rate: 16000\n    labels:\n    - background\n    - speech\n    batch_size: 128\n    shuffle: false\n    test_loss_idx: 0\n    \n","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:39:01 features:305] PADDING: 16\n[NeMo I 2024-07-24 16:39:01 save_restore_connector:275] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc2/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n[NeMo I 2024-07-24 16:39:01 clustering_diarizer:160] Loading pretrained titanet_large model from NGC\n[NeMo I 2024-07-24 16:39:01 cloud:68] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/titanet_large/versions/v1/files/titanet-l.nemo to /root/.cache/torch/NeMo/NeMo_2.0.0rc2/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n[NeMo I 2024-07-24 16:39:03 common:826] Instantiating model from pre-trained checkpoint\n","output_type":"stream"},{"name":"stderr","text":"[NeMo W 2024-07-24 16:39:03 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n    Train config : \n    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n    sample_rate: 16000\n    labels: null\n    batch_size: 64\n    shuffle: true\n    is_tarred: false\n    tarred_audio_filepaths: null\n    tarred_shard_strategy: scatter\n    augmentor:\n      noise:\n        manifest_path: /manifests/noise/rir_noise_manifest.json\n        prob: 0.5\n        min_snr_db: 0\n        max_snr_db: 15\n      speed:\n        prob: 0.5\n        sr: 16000\n        resample_type: kaiser_fast\n        min_speed_rate: 0.95\n        max_speed_rate: 1.05\n    num_workers: 15\n    pin_memory: true\n    \n[NeMo W 2024-07-24 16:39:03 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n    Validation config : \n    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n    sample_rate: 16000\n    labels: null\n    batch_size: 128\n    shuffle: false\n    num_workers: 15\n    pin_memory: true\n    \n","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:39:03 features:305] PADDING: 16\n[NeMo I 2024-07-24 16:39:04 save_restore_connector:275] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc2/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n","output_type":"stream"},{"name":"stderr","text":"[NeMo W 2024-07-24 16:39:04 clustering_diarizer:414] Deleting previous clustering diarizer outputs.\n","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:39:04 speaker_utils:93] Number of files to diarize: 1\n[NeMo I 2024-07-24 16:39:04 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n","output_type":"stream"},{"name":"stderr","text":"splitting manifest: 100%|██████████| 1/1 [00:12<00:00, 12.05s/it]","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:39:16 vad_utils:107] The prepared manifest file exists. Overwriting!\n[NeMo I 2024-07-24 16:39:16 classification_models:293] Perform streaming frame-level VAD\n[NeMo I 2024-07-24 16:39:16 collections:740] Filtered duration for loading collection is  0.00 hours.\n[NeMo I 2024-07-24 16:39:16 collections:741] Dataset successfully loaded with 8 items and total duration provided from manifest is  0.11 hours.\n[NeMo I 2024-07-24 16:39:16 collections:746] # 8 files loaded accounting to # 1 labels\n","output_type":"stream"},{"name":"stderr","text":"\nvad: 100%|██████████| 8/8 [00:01<00:00,  6.48it/s]","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:39:18 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n","output_type":"stream"},{"name":"stderr","text":"\ncreating speech segments: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s]","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:39:18 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, /kaggle/working/diarization_output3/speaker_outputs/subsegments_scale0.json\nINSIDE MODIFIED EXTRACT EMBEDDINGS..\n[NeMo I 2024-07-24 16:39:18 cloud:68] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/ecapa_tdnn/versions/1.16.0/files/ecapa_tdnn.nemo to /root/.cache/torch/NeMo/NeMo_2.0.0rc2/ecapa_tdnn/3e0c5c4731b176aeb70c29a74d800c81/ecapa_tdnn.nemo\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:39:19 common:826] Instantiating model from pre-trained checkpoint\n","output_type":"stream"},{"name":"stderr","text":"[NeMo W 2024-07-24 16:39:20 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n    Train config : \n    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n    sample_rate: 16000\n    labels: null\n    batch_size: 64\n    shuffle: true\n    time_length: 3\n    augmentor:\n      noise:\n        manifest_path: /manifests/noise/rir_noise_manifest.json\n        prob: 0.5\n        min_snr_db: 0\n        max_snr_db: 15\n      speed:\n        prob: 0.5\n        sr: 16000\n        resample_type: kaiser_fast\n        min_speed_rate: 0.95\n        max_speed_rate: 1.05\n    num_workers: 15\n    pin_memory: true\n    \n[NeMo W 2024-07-24 16:39:20 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n    Validation config : \n    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n    sample_rate: 16000\n    labels: null\n    batch_size: 64\n    shuffle: false\n    time_length: 3\n    num_workers: 15\n    pin_memory: true\n    \n","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:39:20 features:305] PADDING: 16\n[NeMo I 2024-07-24 16:39:21 save_restore_connector:275] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc2/ecapa_tdnn/3e0c5c4731b176aeb70c29a74d800c81/ecapa_tdnn.nemo.\n[NeMo I 2024-07-24 16:39:21 clustering_diarizer:349] Extracting embeddings for Diarization\n[NeMo I 2024-07-24 16:39:21 collections:740] Filtered duration for loading collection is  0.00 hours.\n[NeMo I 2024-07-24 16:39:21 collections:741] Dataset successfully loaded with 400 items and total duration provided from manifest is  0.21 hours.\n[NeMo I 2024-07-24 16:39:21 collections:746] # 400 files loaded accounting to # 1 labels\n","output_type":"stream"},{"name":"stderr","text":"[1/3] extract embeddings: 100%|██████████| 7/7 [00:01<00:00,  4.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:39:23 clustering_diarizer:397] Saved embedding files to /kaggle/working/diarization_output3/speaker_outputs/embeddings\n[NeMo I 2024-07-24 16:39:23 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, /kaggle/working/diarization_output3/speaker_outputs/subsegments_scale1.json\nINSIDE MODIFIED EXTRACT EMBEDDINGS..\n[NeMo I 2024-07-24 16:39:23 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc2/ecapa_tdnn/3e0c5c4731b176aeb70c29a74d800c81/ecapa_tdnn.nemo.\n[NeMo I 2024-07-24 16:39:23 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc2/ecapa_tdnn/3e0c5c4731b176aeb70c29a74d800c81/ecapa_tdnn.nemo\n[NeMo I 2024-07-24 16:39:23 common:826] Instantiating model from pre-trained checkpoint\n","output_type":"stream"},{"name":"stderr","text":"[NeMo W 2024-07-24 16:39:25 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n    Train config : \n    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n    sample_rate: 16000\n    labels: null\n    batch_size: 64\n    shuffle: true\n    time_length: 3\n    augmentor:\n      noise:\n        manifest_path: /manifests/noise/rir_noise_manifest.json\n        prob: 0.5\n        min_snr_db: 0\n        max_snr_db: 15\n      speed:\n        prob: 0.5\n        sr: 16000\n        resample_type: kaiser_fast\n        min_speed_rate: 0.95\n        max_speed_rate: 1.05\n    num_workers: 15\n    pin_memory: true\n    \n[NeMo W 2024-07-24 16:39:25 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n    Validation config : \n    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n    sample_rate: 16000\n    labels: null\n    batch_size: 64\n    shuffle: false\n    time_length: 3\n    num_workers: 15\n    pin_memory: true\n    \n","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:39:25 features:305] PADDING: 16\n[NeMo I 2024-07-24 16:39:25 save_restore_connector:275] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc2/ecapa_tdnn/3e0c5c4731b176aeb70c29a74d800c81/ecapa_tdnn.nemo.\n[NeMo I 2024-07-24 16:39:25 clustering_diarizer:349] Extracting embeddings for Diarization\n[NeMo I 2024-07-24 16:39:25 collections:740] Filtered duration for loading collection is  0.00 hours.\n[NeMo I 2024-07-24 16:39:25 collections:741] Dataset successfully loaded with 634 items and total duration provided from manifest is  0.21 hours.\n[NeMo I 2024-07-24 16:39:25 collections:746] # 634 files loaded accounting to # 1 labels\n","output_type":"stream"},{"name":"stderr","text":"[2/3] extract embeddings: 100%|██████████| 10/10 [00:01<00:00,  6.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:39:29 clustering_diarizer:397] Saved embedding files to /kaggle/working/diarization_output3/speaker_outputs/embeddings\n[NeMo I 2024-07-24 16:39:29 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, /kaggle/working/diarization_output3/speaker_outputs/subsegments_scale2.json\nINSIDE MODIFIED EXTRACT EMBEDDINGS..\n[NeMo I 2024-07-24 16:39:29 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc2/ecapa_tdnn/3e0c5c4731b176aeb70c29a74d800c81/ecapa_tdnn.nemo.\n[NeMo I 2024-07-24 16:39:29 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc2/ecapa_tdnn/3e0c5c4731b176aeb70c29a74d800c81/ecapa_tdnn.nemo\n[NeMo I 2024-07-24 16:39:29 common:826] Instantiating model from pre-trained checkpoint\n","output_type":"stream"},{"name":"stderr","text":"[NeMo W 2024-07-24 16:39:30 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n    Train config : \n    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n    sample_rate: 16000\n    labels: null\n    batch_size: 64\n    shuffle: true\n    time_length: 3\n    augmentor:\n      noise:\n        manifest_path: /manifests/noise/rir_noise_manifest.json\n        prob: 0.5\n        min_snr_db: 0\n        max_snr_db: 15\n      speed:\n        prob: 0.5\n        sr: 16000\n        resample_type: kaiser_fast\n        min_speed_rate: 0.95\n        max_speed_rate: 1.05\n    num_workers: 15\n    pin_memory: true\n    \n[NeMo W 2024-07-24 16:39:30 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n    Validation config : \n    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n    sample_rate: 16000\n    labels: null\n    batch_size: 64\n    shuffle: false\n    time_length: 3\n    num_workers: 15\n    pin_memory: true\n    \n","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:39:30 features:305] PADDING: 16\n[NeMo I 2024-07-24 16:39:31 save_restore_connector:275] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc2/ecapa_tdnn/3e0c5c4731b176aeb70c29a74d800c81/ecapa_tdnn.nemo.\n[NeMo I 2024-07-24 16:39:31 clustering_diarizer:349] Extracting embeddings for Diarization\n[NeMo I 2024-07-24 16:39:31 collections:740] Filtered duration for loading collection is  0.00 hours.\n[NeMo I 2024-07-24 16:39:31 collections:741] Dataset successfully loaded with 1525 items and total duration provided from manifest is  0.21 hours.\n[NeMo I 2024-07-24 16:39:31 collections:746] # 1525 files loaded accounting to # 1 labels\n","output_type":"stream"},{"name":"stderr","text":"[3/3] extract embeddings: 100%|██████████| 24/24 [00:02<00:00,  9.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:40:02 clustering_diarizer:397] Saved embedding files to /kaggle/working/diarization_output3/speaker_outputs/embeddings\n","output_type":"stream"},{"name":"stderr","text":"clustering: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:40:03 clustering_diarizer:467] Outputs are saved in /kaggle/working/diarization_output3 directory\n","output_type":"stream"},{"name":"stderr","text":"\n[NeMo W 2024-07-24 16:40:03 nemo_logging:349] /opt/conda/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n      warnings.warn(\n    \n","output_type":"stream"},{"name":"stdout","text":"[NeMo I 2024-07-24 16:40:03 der:176] Cumulative Results for collar 0 sec and ignore_overlap True: \n     FA: 0.0143\t MISS 0.0004\t                 Diarization ER: 0.2303\t, Confusion ER:0.2156\n","output_type":"stream"}]},{"cell_type":"markdown","source":"on audio sample:\nder with titanet only: 23.6%\nder with titanet and ecapa: 23.03%","metadata":{}},{"cell_type":"markdown","source":"on audio sample: der with titanet+ecapa and pca=192  0.95 window size: 22.97\nsame but 0.8 window size: 23.24%","metadata":{}},{"cell_type":"code","source":"trans_info_dict = asr_diar_offline.get_transcript_with_speaker_labels(diar_hyp, word_hyp, word_ts_hyp)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:40:32.363951Z","iopub.execute_input":"2024-07-24T16:40:32.364734Z","iopub.status.idle":"2024-07-24T16:40:32.941038Z","shell.execute_reply.started":"2024-07-24T16:40:32.364699Z","shell.execute_reply":"2024-07-24T16:40:32.940044Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[NeMo I 2024-07-24 16:40:32 diarization_utils:876] Creating results for Session: audio_sample_20 n_spk: 3 \n[NeMo I 2024-07-24 16:40:32 diarization_utils:749] Diarization with ASR output files are saved in: /kaggle/working/diarization_output3/pred_rttms\n","output_type":"stream"}]},{"cell_type":"code","source":"' '.join(word for word in word_hyp['audio_sample_20'])","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:38:21.375084Z","iopub.execute_input":"2024-07-24T16:38:21.375524Z","iopub.status.idle":"2024-07-24T16:38:21.382716Z","shell.execute_reply.started":"2024-07-24T16:38:21.375491Z","shell.execute_reply":"2024-07-24T16:38:21.381652Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'كل ما يتعلق بإسماعيل ياسين وبهجنا يمتعنا يستعيد ذكريات جميله و كمان خلينا نتطلع للأمام ليه لأن إحنا بنتعلم من هذه العموذ الفنيه ما بتموتش أبدا بنعيش على التراث الفني الجميل يعني فا بتحاول تشوفي تستفيدي من يعني هنا إنتي جدك على الشاشه يعني بيبهجنا ويمتعنا يعني بتحاول تشوفي تقولي لما ألقط حاجه من إسماعيل ياسين لما أستفيد حاجه من هذا التاريخ الناصع طبعا إحنا و إحنا صغيرين باباه كان على طول دي فرجنا على أفلامه أه حتى كان في فيلم مبيتعرضش كتير اللي هو إسماعيل ياسين في الجيش هو جايبه و كان حريص جدا إن إحنا نتفرج على أفلامه و كان بيكلمنا على هو في الشغل عامل إزاي يعني كان بيقولنا إن هو كان منضبط جدا بيحب المواعيد ملتزم إن هو شخصيه في الحقيقه جد و مثقف بيحب الايه الحاجات اللي كنت لما بتفرج على إسماعيل ياسين بقى باخدها أو ركز فيها كانت ساعات في إفيهات كده إفيه ذكي الإفيه الذكي أه يشوف إنتي كده بتنقوطي فعلا أه فكان يقول مثلا حاجات فعلا أنا الفيلم أنا مش قادره أفتكر إسمي حاجات مش مبشره فا في فيلم دلوقتي هو هي بتعكس قضيه و بتاع أساسي كان في فيلم ملون إسماعيلي ياسين أيوه العام الفيلم ده في كم إفيهات هما بيتكلموا على عصر قديم جدا بس بحاجات بوقتهم أه فكان الإفيهات بتريليه كريم يبقى في أفلام دلوقتي بيعملوها إسقاط على الواقع يعني أه الإفيهات اللي هو كان بيقولك إفيهات ذكيه يعني في ناس مثلا تطلع تقول إسماعيل ياسين بتاع حركات بق وحركة زي مهرب لأ اللي يركز هيلاقي إنه في كتير إفاد ذكاوي و كان بيقولها طبعا إن هو كان مثقاف ولو يعني مكتبته في الصور بتاعت بيته لأ كان عنده مكتبه كبيره جدا و كان بيحب الكتابه جدا فده بيباين إن في بعد تاني للشخصيه إحنا كنا محظولين إن إحنا سمعنا عنها من بابا وعرفنا البعد التاني من شخصية إسماعيل ياسين وعلى أساس وحياته مشيت إزاي يعني حياته اه و مشاينه تفيجي اللي هو البعض الثقافي ده للبعض يعتقد إنه يعني ممثل كوميديا لكن فعلا إسماعيل ياسين لأ إنتي إنتي جبت الجانب اللي هو التشعري بالثقافه الإفيه الذكي وال والمسؤوليه في في بني آدم عنده مسؤوليه يعني من ضمننا إبليه مثلا في الآخر اشتغل تاني منا لو جست لأنه كان عنده أسره و كان عنده في في بيوتها نفتحها و كان في حاجه رجعلي شغل في الكاميرات أه مانا لو جست أه رجع تاني لأنه كان في عنده مسؤوليه أه إنه ما يقعدش في بإن العامل المادي هنا يقول لما اشتغل يعني هو هو دي صناعته جيل اللي يعرفها جيل اللي اتعلمت مكنش مهينا يعني ياسين مقالش لحضرتك إنه كان قصيا على إسماعيل ياسين نشتغل في الكباريهات من اللوجيس تاني بعد مصانع هزيل الكوكب و كان اسي علينا نفسيا على إسماعين ياسين نفسه في نهاية حياته نشتغل أه إن هو يرجع تاني يقول منلوك لكن كان هو كان لازم يشتغل لازم الحياه تستمر عنده ولد حتتله شكل معين إن هو يربي في ناس مسؤوله في حياته منه فكان لازم يشتغل مكنش ينفع يقعد في البيت الناس لازم يا جماعه أتعلم من الكلام ده و الفنان فعلا لما تقعد تشوف كده الفنان اللي أبهجنا و أمتعنا ده معقوله إنه يعني يضطر للعمل في الكابيهات ويعمل ملوك تاني بعد ما عمل هذه الأفلام إرتبطت بإسمه لكن هي دي في لبنان الصوره دي مع أسرته بابا على سميله وعندنا مراته وعلي يمينه طنط مرمت طنطا ماهره دي بنت خالد بابا واتربيت معاهم وهي عندها سنتين حتى مرحلة لبنان بيتهاجم فيها إنه هو عمل يعني الإعلاميات و إعلان كبيره و معرفش إيه وعلاد كبيره أه و كلام من ده كل الفنانين بيعملوا إعلانت هو عمل مسلسلات تمانينات أه بس و أول رحلة لبان كان مضطر كل الممثلين بعد سبعه و ستين المصريين سافروا كلهم لبنان أه جشمعنا إسماعيل ياسين يعني كلهم صفوت أه ولبنان أنا بتكلم بقى بالنسبه للظروف الفنان أو الفنانين بتوع الزمن الجميل أنا بطلب الدوله إنها لازم موضوع الحق الأداء العالمي أه و هنا بيقلد عبد الوهاب في عيد ميلاد إبنه أه هو كان بيعمل دايما أه هو إبنه الوحيد و دايما بيحب كان بيحتفل بعيد ميلاد بابا في بيته ويعمل احتفال كبير و هو كان بيحب عبد الوهاب جدا و كان في بداية حياته فاكر إن هيطلع هنافس عبد الوهاب فهنا هينافس عدد دلوقتي فعلا مواقف إن هو بيقلد عبد الوهاب في عيد ميلاد إبنه يعني بعد ما بقى نجم أه أه وهو فعلا كان بيغني يعني أه لأ هو كانت هو طالع في أول أنهي لقيناها أيها ركابنا تحت التراب يا فندم عبد الوهاب في فرح فهو فقران كده يصبح عبد الفائع قبل أداء العلم ده لأنه مهم جدا هل كنت إزاي هو هو هو محمد رمضان اعتذر بعد كده لما قال أفلام إسماعيل ياسين أساء للجندي المصري يعني بس هو وضح وعقز أنا بسبب يعني الموضوع ده أنا بطالب سيادة الريس السيسي المكرم إسماعيل ياسين و خاصة في عيد الفن ليه لأن إسماعيل ياسين'"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport json\n\n# Directories\ninput_dir = '/kaggle/working/diarization_output/pred_rttms'\noutput_dir = '/kaggle/working/diarization_VAD_ASR_results'\n\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\ndef process_json_files(input_dir, output_dir):\n    for filename in os.listdir(input_dir):\n        if filename.endswith(\".json\") and \"gecko\" not in filename:\n            input_path = os.path.join(input_dir, filename)\n            output_path = os.path.join(output_dir, filename)\n            \n            # Read the JSON file\n            with open(input_path, 'r', encoding='utf-8') as file:\n                data = json.load(file)\n            \n            # Save the updated JSON to the new directory\n            with open(output_path, 'w', encoding='utf-8') as file:\n                json.dump(data, file, ensure_ascii=False, indent=4)\n\nprocess_json_files(input_dir, output_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T02:32:09.513890Z","iopub.execute_input":"2024-07-24T02:32:09.514851Z","iopub.status.idle":"2024-07-24T02:32:10.041284Z","shell.execute_reply.started":"2024-07-24T02:32:09.514816Z","shell.execute_reply":"2024-07-24T02:32:10.040376Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# save in desired format","metadata":{}},{"cell_type":"code","source":"import os\nimport json\n\n# Directories\ninput_dir = '/kaggle/working/diarization_VAD_ASR_results'\noutput_dir = '/kaggle/working/diarization_VAD_ASR_results_final'\n\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\ndef transform_json(input_dir, output_dir):\n    for filename in os.listdir(input_dir):\n        input_path = os.path.join(input_dir,filename)\n        with open(input_path, 'r', encoding='utf-8') as infile:\n            data = json.load(infile)\n\n        transformed_data = []\n\n        for sentence in data.get('sentences', []):\n            transformed_data.append({\n                \"start\": float(sentence['start_time']),\n                \"end\": float(sentence['end_time']),\n                \"speaker\": int(sentence['speaker'].replace(\"speaker_\", \"\")),\n                \"text\": sentence['text']\n            })\n        output_path = os.path.join(output_dir,filename)\n        with open(output_path, 'w', encoding='utf-8') as outfile:\n            json.dump(transformed_data, outfile, ensure_ascii=False, indent=4)\n\n\ntransform_json(input_dir, output_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T02:32:16.387708Z","iopub.execute_input":"2024-07-24T02:32:16.388151Z","iopub.status.idle":"2024-07-24T02:32:16.520636Z","shell.execute_reply.started":"2024-07-24T02:32:16.388116Z","shell.execute_reply":"2024-07-24T02:32:16.519445Z"},"trusted":true},"execution_count":28,"outputs":[]}]}